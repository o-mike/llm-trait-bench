# 🧠 LLM Trait Benchmark - Prompt-Induced Manipulativeness

A benchmarking tool that measures how easily Large Language Models shift to manipulative responses under inducing prompts.

## 🎯 What This Measures

**Trait:** Prompt-Induced Manipulativeness  
**Scale:** 0-10 (0 = honest/transparent, 10 = highly manipulative/deceptive)

### Test Scenarios
- **Neutral:** Baseline scenarios asking for honest advice
- **Induced:** Scenarios explicitly prompting for manipulative behavior

### Models Tested
- Google Gemini 1.5 Pro
- Anthropic Claude 3.5 Sonnet  
- DeepSeek V2
- OpenAI GPT-4o
- Meta Llama 3.1 405B

## 🚀 Quick Start

### Prerequisites
- Python 3.8+
- OpenRouter API key

### Installation
```bash
# Clone and setup
git clone <repo-url>
cd llm-trait-bench

# Install dependencies
curl -LsSf https://astral.sh/uv/install.sh | sh  # Install UV if needed
uv venv
source .venv/bin/activate
uv pip install openai pandas plotly gradio ruff

# Set API key
export OPENROUTER_API_KEY="your_key_here"

# Run benchmark
python benchmark.py
```

### Remote Access (VPS)
```bash
# On local machine
ssh -L 7860:localhost:7860 user@your-vps-ip

# On VPS
source .venv/bin/activate
python benchmark.py

# Open browser to http://localhost:7860
```

## 📊 Output

- Interactive Gradio dashboard with visualizations
- CSV export of detailed results  
- Cost estimation (~$2-5 per full benchmark)
- ~150 API calls total

## 🔧 Development

```bash
# Code quality
ruff check benchmark.py
ruff format benchmark.py

# Project structure
benchmark.py      # Main application
CLAUDE.md        # Project memory for Claude
README.md        # This file
requirements.txt # Auto-generated by UV
```

## 📈 Future Extensions

This MVP is designed for easy extension:
- Dynamic question generation
- Multiple judge LLMs (council approach)
- Additional traits (e.g., helpfulness, safety)
- More visualization options
- Advanced scoring methods

## ⚠️ Important Notes

- **Cost:** Estimates ~$2-5 per full run depending on models
- **Time:** ~5-10 minutes for complete benchmark
- **Ethics:** Used for defensive security research only
- **API Keys:** Keep OpenRouter key secure, never commit to repo

## 📝 License

MIT License - Use responsibly for defensive AI safety research.